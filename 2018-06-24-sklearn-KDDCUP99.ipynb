{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Cyber Security\n",
    "* Learn to spot an attacker through monitoring TCP logs.\n",
    "\n",
    "## Dataset: KDD Cup 1999\n",
    "* [Source](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) `[1]`\n",
    "* TCP data dump - array of 41 variables (TCP features)\n",
    "    * Basic Features (9)\n",
    "    * Content Features (13)\n",
    "    * Traffic Features (19)\n",
    "* Consists of 23 types of attacks:\n",
    "    1. DOS: back, land, neptune, pod, surf, teardrop\n",
    "    2. R2L: ftp_write, guess_passwd, lmap, multihop, phf, spy, warezclient, warezmaster\n",
    "    3. U2R: buffer_overflow, loadmodule, perl, rootkit\n",
    "    4. Probing: ipsweep, nmap, portsweep, satan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Features of TCP\n",
    "* `duration` - connection time in seconds.\n",
    "* `protocal_type` - i.e. TCP, UDP\n",
    "* `service` - Netword service on destination (i.e. HTTP, Telnet)\n",
    "* `source_bytes` - amount of data from source to destination.\n",
    "* `flag` - normal or error status of connection.\n",
    "* `land` - Connection is from/to the same host/port: \"1\", else \"0\".\n",
    "* `wrong_fragment` - number of \"wrong\" fragments.\n",
    "* `urgent` - number of urgent packets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Features of TCP\n",
    "* `host` - number of \"hot\" indicators.\n",
    "* `num_failed_logins` - number of attempts.\n",
    "* `logged_in` - succes: \"1\", else \"0\".\n",
    "* `compromised` - number of \"compromised\" conditions.\n",
    "* `root_shell` - if root shell obtained: \"1\", else \"0\".\n",
    "* `su_attempted` - if \"su\" command attempted: \"1\", else \"0\".\n",
    "* `num_root` - number of root accesses.\n",
    "* `num_file_creations` - number of creation operations.\n",
    "* `num_shells` - number of shell prompts.\n",
    "* `num_access_files` - number of operations on access control files.\n",
    "* `num_outbound_cmds` - number per session.\n",
    "* `is_hot_login` - if login on \"hot\" list: \"1\", else \"0\".\n",
    "* `is_guest_login` - if guest: \"1\", else \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Features of TCP (2 sec window)\n",
    "* `count` - number of connections to the same host.\n",
    "* `serror_rate` - % of connections with \"SYN\" errors.\n",
    "* `rerror_rate` - % of connections with \"REJ\" errors.\n",
    "* `same_srv_rate` - % of connections to the same service.\n",
    "* `diff_srv_rate` - % of connections to different services.\n",
    "* `srv_count` - number of connections to the same service.\n",
    "* `srv_serror_rate` - % of connections with \"SYN\" errors.\n",
    "* `srv_rerror_rate` - % of connections with \"REJ\" errors.\n",
    "* `srv_diff_host_rate` - % of connections to different hosts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (from [scikit-learn](http://scikit-learn.org/stable/))\n",
    "\n",
    "* Generative:\n",
    "    * Naive Bayes\n",
    "* Descriminative:\n",
    "    * kNN\n",
    "    * kMeans\n",
    "    * Logistic Regression\n",
    "    * Decision Tree\n",
    "    * Random Forest\n",
    "* Others to consider:\n",
    "    * LinearDiscriminantAnalysis\n",
    "    * GaussianNB\n",
    "    * NBTree, Random Tree, Multilayer Perceptron (additional models from `[2]`)\n",
    "    * SVC (Not used for this problem. \"The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_part = fetch_kddcup99(percent10=True)  # Over 600 MB in memeory.\n",
    "# dataset_full = fetch_kddcup99(percent10=False)  # Crashed my computer with 16 GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, b'tcp', b'http', b'SF', 181, 5450, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 8, 8, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9, 9,\n",
       "       1.0, 0.0, 0.11, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_part.data[0]  # Sample of TCP record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset_part.target))  # Number of unique classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data\n",
    "* Dataset values are all of type \"object\" => convert to numeric types.\n",
    "* [Label Encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) - replaces strings with an incrementing integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset_part.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0       1        2      3    4     5  6  7  8  9  ... 31 32 33 34    35 36  \\\n",
       "0  0  b'tcp'  b'http'  b'SF'  181  5450  0  0  0  0 ...  9  9  1  0  0.11  0   \n",
       "\n",
       "  37 38 39 40  \n",
       "0  0  0  0  0  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "'''\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(names))\n",
    "# le.classes_  # Shows all labels.\n",
    "print(le.transform([b'icmpeco_iSF', b'icmpecr_iSF', b'icmpred_iSF']) )\n",
    "print(le.inverse_transform([0, 0, 1, 2]))\n",
    "'''\n",
    "# https://datascience.stackexchange.com/questions/16728/could-not-convert-string-to-float-error-on-kddcup99-dataset\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == object:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3    4     5   6   7   8   9  ...   31  32   33   34    35  \\\n",
       "0   0   1  22   9  181  5450   0   0   0   0 ...    9   9  1.0  0.0  0.11   \n",
       "\n",
       "    36   37   38   39   40  \n",
       "0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)  # All strings removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(dataset_part.target)\n",
    "y_dict = dict(zip(y,le.classes_))  # Saved for later lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "N_SPLITS = 7\n",
    "SCORING = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "test_size=0.33\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     mean    std   \n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 10.8 s per loop\n",
      "LDA      99.49%  0.05%  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#  Algorithms\n",
    "models = [\n",
    "          #('LR', LogisticRegression()),\n",
    "          ('LDA', LinearDiscriminantAnalysis()),\n",
    "          #('KNN', KNeighborsClassifier()),\n",
    "          #('KMN', KMeans()),\n",
    "          #('CART', DecisionTreeClassifier()),\n",
    "          #('NB', GaussianNB()),\n",
    "         ]\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "print('{:8}{:^8}{:^8}'.format('Model','mean','std'))\n",
    "print('-' * 23)\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=N_SPLITS, random_state=SEED)\n",
    "\n",
    "    %timeit -n1 cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=SCORING) \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('{:8}{:^8.2%}{:^8.2%}'.format(name, cv_results.mean(), cv_results.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994924394628 0.995664587078 0.99452257587 0.994607169293 0.994205350534 0.995241619964 0.995135775315\n"
     ]
    }
   ],
   "source": [
    "print(*cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_results = '''\n",
    "LR: 98.87% (0.10%)\n",
    "LDA: 99.49% (0.05%)\n",
    "KNN: 99.84% (0.01%) <-- slow\n",
    "CART: 99.94% (0.00%)\n",
    "NB: 93.96% (0.96%)\n",
    "SVM:   <-- very slow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [0, 1, 22, 9, 181, 5450, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9, 9, 1.0, 0.0, 0.11, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "print(neigh.predict([test]))\n",
    "\n",
    "print(neigh.predict_proba([test]))  # TODO: research this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "* `[1]` - [KDD Cup 99 dataset](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\n",
    "* `[2]` - M. Tavallaee, E. Bagheri, W. Lu, and A. Ghorbani, “**A Detailed Analysis of the KDD CUP 99 Data Set,**” *Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA)*, 2009. [link](http://ieeexplore.ieee.org/document/5356528/)\n",
    "\n",
    "## Other Resources\n",
    "\n",
    "* [PySpark solution to the KDDCup99](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiy0d3MntLWAhVKzlQKHdUCBmEQFggwMAE&url=https%3A%2F%2Fgithub.com%2Fjadianes%2Fkdd-cup-99-spark&usg=AOvVaw2A8ZaswhhYORBDfFTH-sZJ)\n",
    "\n",
    "#### [link](https://www.quora.com/Where-can-I-get-the-latest-dataset-for-a-network-intrusion-detection-system)\n",
    "\n",
    "* Logs\n",
    "    * [Public PCAP files](http://www.netresec.com/?page=PcapFiles) for PCAP-based evaluation of network-based intrusion detection system (NIDS) evaluation.\n",
    "    * [The Cyber Research Center - DataSets - ITOC CDX](http://www.westpoint.edu/crc/SitePages/DataSets.aspx) (2009)\n",
    "    \n",
    "* Labelled datasets\n",
    "    * [UNB ISCX (2012-)](http://www.unb.ca/research/iscx/dataset/index.html) datasets contain a range of \"sophisticated\" intrusion attacks, botnets and DoS attacks.\n",
    "    * [CSIC 2010 HTTP Dataset](http://bit.ly/csic-2010-http-dataset-csv) in CSV format (for Weka Analysis) dataset is from a web penetration testing testbed for anomaly detection training.\n",
    "    * [Attack Challenge - ECML/PKDD Workshop](http://www2.lirmm.fr/pkdd2007-challenge/#dataset) (2007) dataset contains web penetration testing data.\n",
    "    * [NSL-KDD Data Set](http://nsl.cs.unb.ca/NSL-KDD/) (2007) intended to replace the DARPA KDDCup99 dataset for IDS.\n",
    "    * [gureKddcup data base](http://www.sc.ehu.es/acwaldap/gureKddcup/galdetegia_jaso.php) (2008) intended to replace the DARPA KDDCup99 dataset for IDS.\n",
    "    * [CTU-13 dataset](https://stratosphereips.org/category/dataset.html) - pcap files (Stratosphere IPS).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go from here\n",
    "\n",
    "* Seeking more labelled datasets and determining the potential for other non-labelled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('{:10}{:10}{:10}'.format('Model','mean','std'))\n",
    "print('LDA: 99.49% (0.05%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     mean    std   \n",
      "-----------------------\n",
      "LDA      99.49%  0.05%  \n"
     ]
    }
   ],
   "source": [
    "print('{:8}{:^8}{:^8}'.format('Model','mean','std'))\n",
    "print('-' * 23)\n",
    "print('{:8}{:^8.2%}{:^8.2%}'.format('LDA', .9949, .0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "    * Add `%timeit` to each model being trained.\n",
    "    * Compare times to a compute cluster using PySpark.\n",
    "    * Add more models (KMeans).\n",
    "    * Graph accuracy vs. k (or similar factor for all models).\n",
    "    * Compare all models (accuracy, train time, predict time).\n",
    "    * Refactor code to allow various datasets.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
